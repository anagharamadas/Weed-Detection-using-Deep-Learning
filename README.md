Chemical pesticide spraying over a large area is not only a waste of herbicides and labour, but it also pollutes the environment and compromises food quality. As a result, properly identifying weeds and spraying them are critical tactics for increasing agricultural sustainability. In this work, the models were trained using a dataset containing 17,509 labelled images of weeds native to Australia. Despite the advances of Deep learning models, it still faces challenges like high computational power, overfitting and need of a balanced labelled dataset, therefore transformers used mainly in Natural language processing tasks can be considered as a possible replacement for CNNs. 
	


### Project Overview

This project aims to:
- analyse and compare Vision Transformer with CNN models for achieving good results on weed detection and classification from crop images. 
- focuses on distinguishing between grass and broadleaf weeds, leveraging advanced neural network architectures for accurate classification.
- Provide a modular pipeline for training and testing weed classification models.

### Features

- **Dataset Preprocessing:** Handles datasets containing images of grass and broadleaf weeds.

- **Model Architectures:** Implements state-of-the-art convolutional neural networks - ResNet-50, Xception, Inception V3 and, Inception-Resnet V2

- **Training and Validation:** Includes scripts to train models on weed datasets and evaluate their performance.

- **Visualization:** Jupyter Notebook for visualizing results and analyzing model predictions.


	
As the final results of the experiment, the Vision transformer gave the highest accuracy of 96.41% followed by the ResNet-50 model which gave an accuracy of 95.70% compared to 95.04% of the Xception model. The Inception V3 model gave an accuracy of 94.7% and Inception-Resnet V2 gave an accuracy of 94.15% on the dataset images.

 Detailed description given in the pdf attached.
